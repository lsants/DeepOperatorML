#  ----------------------Location of .npz data file ----------------
DATA_FILE: ./data/raw/dynamic_displacements.npz

# ------------------------------ Paths ------------------------
# Model location
MODEL_FOLDER: ./models/

OUTPUT_FOLDER_TO_SAVE: ./data/output/

# ------------------------- Dataset parameters ---------------
PROBLEM: dynamic

INPUT_FUNCTION_KEYS: # F, mu, nu if Kelvin ; delta if dynamic with fixed material
  -  delta

COORDINATE_KEYS:
  - r
  - z

OUTPUT_KEYS:
  - g_u_real
  - g_u_imag

OUTPUT_LABELS:
  - "$\\Re(\\vec{u})$"
  - "$\\Im(\\vec{u})$"

DIRECTION: 2

# ------------------- Model architecture ------------------
PRECISION: float32
DEVICE: cpu
SEED: 42

TRAINING_STRATEGY: pod
OUTPUT_HANDLING: share_trunk
BASIS_FUNCTIONS: 100
BRANCH_ARCHITECTURE: resnet
BRANCH_ACTIVATION: silu
BRANCH_DEGREE: 8
BRANCH_HIDDEN_LAYERS:
  - 100 
  - 100 
  - 100 
  - 100 
  - 100 
  - 100 

TRUNK_ARCHITECTURE: resnet
TRUNK_ACTIVATION: silu
TRUNK_DEGREE: 8
TRUNK_HIDDEN_LAYERS:
  - 100 
  - 100 
  - 100 
  - 100 
  - 100 
  - 100 

LOSS_FUNCTION: mse
INPUT_NORMALIZATION: true # allow to pick between min max and std 
OUTPUT_NORMALIZATION: false
TRUNK_FEATURE_EXPANSION: 2
RESCALING: none # p = number of basis functions. Can be none, 1/p or 1/sqrt(p)

# ------------------- Parameters for vanilla training ------------------
LEARNING_RATE: 0.001
EPOCHS: 500
BATCH_SIZE: 50
TRAIN_PERC: 0.8
VAL_PERC: 0.1
TEST_PERC: 0.1
ERROR_NORM: 2
STANDARD_PROGRESS_BAR_COLOR: 'green'
OPTIMIZER_SCHEDULE: 
  - EPOCHS: 5000
    OPTIMIZER: adam
    LEARNING_RATE: 0.001
    L2_REGULARIZATION: 0.00001
    # LR_SCHEDULER:
    #   STEP_SIZE: 2000
    #   GAMMA: 0.7
  - EPOCHS: 4000
    OPTIMIZER: adam
    LEARNING_RATE: 0.001
    L2_REGULARIZATION: 0.00001


# ------------------- Parameters for POD training ----------------------
VAR_SHARE: 0.95

# ------------------- Parameters for two step training ------------------
TRUNK_TRAIN_EPOCHS: 100
BRANCH_TRAIN_EPOCHS: 500

TRUNK_DECOMPOSITION: svd